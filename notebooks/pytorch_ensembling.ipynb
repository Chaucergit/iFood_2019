{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing pip packages for pretrained models\n",
    "!pip install pretrainedmodels\n",
    "#importing packages\n",
    "import os,time\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import numpy as np\n",
    "import pretrainedmodels\n",
    "from tqdm import tqdm\n",
    "import torch.optim.lr_scheduler as lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if GPU is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU available: \",use_cuda)\n",
    "\n",
    "class FCWithLogSigmoid(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super(FCWithLogSigmoid, self).__init__()\n",
    "        self.linear = nn.Linear(num_inputs, num_outputs)\n",
    "        self.logsigmoid = nn.LogSigmoid()\n",
    "    def forward(self, x):\n",
    "        return self.logsigmoid(self.linear(x))\n",
    "    \n",
    "\n",
    "#Specifying senet model\n",
    "model_name = 'senet154' # could be fbresnet152 or inceptionresnetv2\n",
    "model_senet = pretrainedmodels.__dict__[model_name](pretrained=None) #pretrained='imagenet+background'\n",
    "\n",
    "for param in model_senet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_senet.last_linear = FCWithLogSigmoid(2048, 251)\n",
    "\n",
    "model_senet.load_state_dict(torch.load('../input/models-v2/pytorch_senet.pt'))\n",
    "\n",
    "#Specifying pnasnet model\n",
    "model_name = 'pnasnet5large'\n",
    "model_pnasnet = pretrainedmodels.__dict__[model_name](pretrained=None) #pretrained='imagenet+background'\n",
    "\n",
    "for param in model_pnasnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_pnasnet.last_linear = FCWithLogSigmoid(4320, 251)\n",
    "    \n",
    "model_pnasnet.load_state_dict(torch.load('../input/models-v2/pytorch_pnasnet.pt'))\n",
    "\n",
    "#Specifying polynet model\n",
    "model_name = 'polynet' # could be fbresnet152 or inceptionresnetv2\n",
    "model_polynet = pretrainedmodels.__dict__[model_name](pretrained=None) #pretrained='imagenet+background'\n",
    "\n",
    "for param in model_polynet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_polynet.last_linear = FCWithLogSigmoid(2048, 251)\n",
    "    \n",
    "model_polynet.load_state_dict(torch.load('../input/models-aug/pytorch_polynet.pt'))\n",
    "\n",
    "#Specifying densenet201 model\n",
    "model_densenet = models.densenet201(pretrained=False)\n",
    "\n",
    "for param in model_densenet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_densenet.classifier = FCWithLogSigmoid(1920, 251)\n",
    "    \n",
    "    \n",
    "model_densenet.load_state_dict(torch.load('../input/densenet-v2/pytorch_densenet201.pt'))\n",
    "\n",
    "\n",
    "if use_cuda:\n",
    "    model_senet = model_senet.cuda()\n",
    "    model_pnasnet = model_pnasnet.cuda()\n",
    "    model_polynet = model_polynet.cuda()\n",
    "    model_densenet = model_densenet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {0: '0', 1: '1', 2: '10', 3: '100', 4: '101', 5: '102', 6: '103', 7: '104', 8: '105', 9: '106', 10: '107', 11: '108', 12: '109', 13: '11', 14: '110', 15: '111', 16: '112', 17: '113', 18: '114', 19: '115', 20: '116', 21: '117', 22: '118', 23: '119', 24: '12', 25: '120', 26: '121', 27: '122', 28: '123', 29: '124', 30: '125', 31: '126', 32: '127', 33: '128', 34: '129', 35: '13', 36: '130', 37: '131', 38: '132', 39: '133', 40: '134', 41: '135', 42: '136', 43: '137', 44: '138', 45: '139', 46: '14', 47: '140', 48: '141', 49: '142', 50: '143', 51: '144', 52: '145', 53: '146', 54: '147', 55: '148', 56: '149', 57: '15', 58: '150', 59: '151', 60: '152', 61: '153', 62: '154', 63: '155', 64: '156', 65: '157', 66: '158', 67: '159', 68: '16', 69: '160', 70: '161', 71: '162', 72: '163', 73: '164', 74: '165', 75: '166', 76: '167', 77: '168', 78: '169', 79: '17', 80: '170', 81: '171', 82: '172', 83: '173', 84: '174', 85: '175', 86: '176', 87: '177', 88: '178', 89: '179', 90: '18', 91: '180', 92: '181', 93: '182', 94: '183', 95: '184', 96: '185', 97: '186', 98: '187', 99: '188', 100: '189', 101: '19', 102: '190', 103: '191', 104: '192', 105: '193', 106: '194', 107: '195', 108: '196', 109: '197', 110: '198', 111: '199', 112: '2', 113: '20', 114: '200', 115: '201', 116: '202', 117: '203', 118: '204', 119: '205', 120: '206', 121: '207', 122: '208', 123: '209', 124: '21', 125: '210', 126: '211', 127: '212', 128: '213', 129: '214', 130: '215', 131: '216', 132: '217', 133: '218', 134: '219', 135: '22', 136: '220', 137: '221', 138: '222', 139: '223', 140: '224', 141: '225', 142: '226', 143: '227', 144: '228', 145: '229', 146: '23', 147: '230', 148: '231', 149: '232', 150: '233', 151: '234', 152: '235', 153: '236', 154: '237', 155: '238', 156: '239', 157: '24', 158: '240', 159: '241', 160: '242', 161: '243', 162: '244', 163: '245', 164: '246', 165: '247', 166: '248', 167: '249', 168: '25', 169: '250', 170: '26', 171: '27', 172: '28', 173: '29', 174: '3', 175: '30', 176: '31', 177: '32', 178: '33', 179: '34', 180: '35', 181: '36', 182: '37', 183: '38', 184: '39', 185: '4', 186: '40', 187: '41', 188: '42', 189: '43', 190: '44', 191: '45', 192: '46', 193: '47', 194: '48', 195: '49', 196: '5', 197: '50', 198: '51', 199: '52', 200: '53', 201: '54', 202: '55', 203: '56', 204: '57', 205: '58', 206: '59', 207: '6', 208: '60', 209: '61', 210: '62', 211: '63', 212: '64', 213: '65', 214: '66', 215: '67', 216: '68', 217: '69', 218: '7', 219: '70', 220: '71', 221: '72', 222: '73', 223: '74', 224: '75', 225: '76', 226: '77', 227: '78', 228: '79', 229: '8', 230: '80', 231: '81', 232: '82', 233: '83', 234: '84', 235: '85', 236: '86', 237: '87', 238: '88', 239: '89', 240: '9', 241: '90', 242: '91', 243: '92', 244: '93', 245: '94', 246: '95', 247: '96', 248: '97', 249: '98', 250: '99'}\n",
    "order_val = list(labels.values())\n",
    "order_keys = list(labels.keys())\n",
    "order = [order_val.index(str(i)) for i in order_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making predictions on test data by making batches manually\n",
    "from PIL import Image\n",
    "import random,cv2\n",
    "val_path = \"../input/ifood-2019-fgvc6/test_set/test_set/\"\n",
    "batch_size = 64\n",
    "val_images = os.listdir(val_path)\n",
    "images_complete = val_images[:(len(os.listdir(val_path))//batch_size)*batch_size]\n",
    "images_partial = val_images[(len(os.listdir(val_path))//batch_size)*batch_size:]\n",
    "\n",
    "transform_senet = transforms.Compose([transforms.CenterCrop(224),\n",
    "                                 transforms.ToTensor(), \n",
    "                                 transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                          std=[0.229, 0.224, 0.225])])\n",
    "transform_pnasnet = transforms.Compose([transforms.CenterCrop(331),\n",
    "                                 transforms.ToTensor(), \n",
    "                                 transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                          std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "transform_polynet = transforms.Compose([transforms.CenterCrop(331),\n",
    "                                 transforms.ToTensor(), \n",
    "                                 transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                          std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "transform_densenet = transforms.Compose([transforms.CenterCrop(224),\n",
    "                                 transforms.ToTensor(), \n",
    "                                 transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                          std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "  \n",
    "\n",
    "data_senet = []\n",
    "data_pnasnet = []\n",
    "data_polynet = []\n",
    "data_densenet = []\n",
    "image_names = []\n",
    "for i in tqdm(range(len(images_complete))):\n",
    "    image = Image.open(val_path+images_complete[i])\n",
    "    \n",
    "    image_senet = transform_senet(image).float()\n",
    "    image_senet = image_senet.unsqueeze(0)\n",
    "    \n",
    "    image_pnasnet = transform_pnasnet(image).float()\n",
    "    image_pnasnet = image_pnasnet.unsqueeze(0)\n",
    "    \n",
    "    image_polynet = transform_polynet(image).float()\n",
    "    image_polynet = image_polynet.unsqueeze(0)\n",
    "    \n",
    "    image_densenet = transform_densenet(image).float()\n",
    "    image_densenet = image_densenet.unsqueeze(0)\n",
    "    \n",
    "    #print(image.shape)\n",
    "    data_senet.append(image_senet)\n",
    "    data_pnasnet.append(image_pnasnet)\n",
    "    data_polynet.append(image_polynet)\n",
    "    data_densenet.append(image_densenet)\n",
    "    image_names.append(images_complete[i])\n",
    "\n",
    "    if (len(data_senet) == batch_size):\n",
    "        t = 0\n",
    "        batch_index = []\n",
    "        batch_index_top3 = []\n",
    "        first_tensor_data_senet = data_senet[t]\n",
    "        first_tensor_data_pnasnet = data_pnasnet[t]\n",
    "        first_tensor_data_polynet = data_polynet[t]\n",
    "        first_tensor_data_densenet = data_densenet[t]\n",
    "        while(t<(batch_size-1)):\n",
    "            second_tensor_data_senet = data_senet[t+1]\n",
    "            second_tensor_data_pnasnet = data_pnasnet[t+1]\n",
    "            second_tensor_data_polynet = data_polynet[t+1]\n",
    "            second_tensor_data_densenet = data_densenet[t+1]\n",
    "            \n",
    "            data_tensor_senet = torch.cat((first_tensor_data_senet,second_tensor_data_senet),dim=0)\n",
    "            data_tensor_pnasnet = torch.cat((first_tensor_data_pnasnet,second_tensor_data_pnasnet),dim=0)\n",
    "            data_tensor_polynet = torch.cat((first_tensor_data_polynet,second_tensor_data_polynet),dim=0)\n",
    "            data_tensor_densenet = torch.cat((first_tensor_data_densenet,second_tensor_data_densenet),dim=0)\n",
    "  \n",
    "            \n",
    "            first_tensor_data_senet = data_tensor_senet\n",
    "            first_tensor_data_pnasnet = data_tensor_pnasnet\n",
    "            first_tensor_data_polynet = data_tensor_polynet\n",
    "            first_tensor_data_densenet = data_tensor_densenet\n",
    "            \n",
    "            t+=1\n",
    "        if use_cuda:\n",
    "            data_tensor_senet = data_tensor_senet.cuda()\n",
    "            data_tensor_pnasnet = data_tensor_pnasnet.cuda()\n",
    "            data_tensor_polynet = data_tensor_polynet.cuda()\n",
    "            data_tensor_densenet = data_tensor_densenet.cuda()\n",
    "        #print(data_tensor.shape)\n",
    "        output_senet = model_senet(data_tensor_senet)\n",
    "        output_pnasnet = model_pnasnet(data_tensor_pnasnet)\n",
    "        output_polynet = model_polynet(data_tensor_polynet)\n",
    "        output_densenet = model_densenet(data_tensor_densenet)\n",
    "        \n",
    "        arr_densenet = output_densenet.data.cpu().numpy()\n",
    "        res_densenet = []\n",
    "        for i in range(arr_densenet.shape[0]):\n",
    "            res_densenet.append([arr_densenet[i][j] for j in order])\n",
    "        index_densenet = res_densenet\n",
    "        index_densenet=np.array(index_densenet)\n",
    "        \n",
    "        #print(output.shape)\n",
    "        index_senet = output_senet.data.cpu().numpy()\n",
    "        index_pnasnet = output_pnasnet.data.cpu().numpy()  \n",
    "        index_polynet = output_polynet.data.cpu().numpy()\n",
    "        #index_densenet = output_densenet.data.cpu().numpy()\n",
    "        \n",
    "        index = np.add(index_senet,index_pnasnet)\n",
    "        index = np.add(index,index_polynet)\n",
    "        index = np.add(index,index_densenet)\n",
    "        index /=4\n",
    "        for k in index:\n",
    "            mini_batch_index = k.argsort()[::-1][:3]\n",
    "            batch_index.append(mini_batch_index)\n",
    "            \n",
    "        assert len(image_names) == len(batch_index)\n",
    "        \n",
    "        with open(\"pytorch_ensembling_4models.txt\",\"a\") as f:\n",
    "            for l in range(len(image_names)):\n",
    "                f.write(image_names[l]+','+str(batch_index[l][0])+' '+str(batch_index[l][1])+' '+\n",
    "                        str(batch_index[l][2])+'\\n')\n",
    "        data_senet = []\n",
    "        data_pnasnet = []\n",
    "        data_polynet = []\n",
    "        data_densenet = []\n",
    "        image_names = []\n",
    "\n",
    "data_senet = []\n",
    "data_pnasnet = []\n",
    "data_polynet = []\n",
    "data_densenet = []\n",
    "image_names = []\n",
    "for i in tqdm(range(len(images_partial))):\n",
    "    image = Image.open(val_path+images_partial[i])\n",
    "    image_senet = transform_senet(image).float()\n",
    "    image_senet = image_senet.unsqueeze(0)\n",
    "    \n",
    "    image_pnasnet = transform_pnasnet(image).float()\n",
    "    image_pnasnet = image_pnasnet.unsqueeze(0)\n",
    "    \n",
    "    image_polynet = transform_polynet(image).float()\n",
    "    image_polynet = image_polynet.unsqueeze(0)\n",
    "    \n",
    "    image_densenet = transform_densenet(image).float()\n",
    "    image_densenet = image_densenet.unsqueeze(0)\n",
    "    \n",
    "    #print(image.shape)\n",
    "    data_senet.append(image_senet)\n",
    "    data_pnasnet.append(image_pnasnet)\n",
    "    data_polynet.append(image_polynet)\n",
    "    data_densenet.append(image_densenet)\n",
    "    image_names.append(images_partial[i])\n",
    "\n",
    "    if (len(data_senet) == len(images_partial)):\n",
    "        t = 0\n",
    "        batch_index = []\n",
    "        batch_index_top3 = []\n",
    "        first_tensor_data_senet = data_senet[t]\n",
    "        first_tensor_data_pnasnet = data_pnasnet[t]\n",
    "        first_tensor_data_polynet = data_polynet[t]\n",
    "        first_tensor_data_densenet = data_densenet[t]\n",
    "        \n",
    "        while(t<(len(images_partial)-1)):\n",
    "            second_tensor_data_senet = data_senet[t+1]\n",
    "            second_tensor_data_pnasnet = data_pnasnet[t+1]\n",
    "            second_tensor_data_polynet = data_polynet[t+1]\n",
    "            second_tensor_data_densenet = data_densenet[t+1]\n",
    "            \n",
    "            data_tensor_senet = torch.cat((first_tensor_data_senet,second_tensor_data_senet),dim=0)\n",
    "            data_tensor_pnasnet = torch.cat((first_tensor_data_pnasnet,second_tensor_data_pnasnet),dim=0)\n",
    "            data_tensor_polynet = torch.cat((first_tensor_data_polynet,second_tensor_data_polynet),dim=0)\n",
    "            data_tensor_densenet = torch.cat((first_tensor_data_densenet,second_tensor_data_densenet),dim=0)\n",
    "    \n",
    "            \n",
    "            first_tensor_data_senet = data_tensor_senet\n",
    "            first_tensor_data_pnasnet = data_tensor_pnasnet\n",
    "            first_tensor_data_polynet = data_tensor_polynet\n",
    "            first_tensor_data_densenet = data_tensor_densenet\n",
    "            \n",
    "            t+=1\n",
    "        if use_cuda:\n",
    "            data_tensor_senet = data_tensor_senet.cuda()\n",
    "            data_tensor_pnasnet = data_tensor_pnasnet.cuda()\n",
    "            data_tensor_polynet = data_tensor_polynet.cuda()\n",
    "            data_tensor_densenet = data_tensor_densenet.cuda()\n",
    "        #print(data_tensor.shape)\n",
    "        output_senet = model_senet(data_tensor_senet)\n",
    "        output_pnasnet = model_pnasnet(data_tensor_pnasnet)\n",
    "        output_polynet = model_polynet(data_tensor_polynet)\n",
    "        output_densenet = model_densenet(data_tensor_densenet)\n",
    "        \n",
    "        arr_densenet = output_densenet.data.cpu().numpy()\n",
    "        res_densenet = []\n",
    "        for i in range(arr_densenet.shape[0]):\n",
    "            res_densenet.append([arr_densenet[i][j] for j in order])\n",
    "        index_densenet = res_densenet\n",
    "        index_densenet=np.array(index_densenet)\n",
    "        \n",
    "        #print(output.shape)\n",
    "        index_senet = output_senet.data.cpu().numpy()\n",
    "        index_pnasnet = output_pnasnet.data.cpu().numpy()\n",
    "        index_polynet = output_polynet.data.cpu().numpy()\n",
    "        #index_densenet = output_densenet.data.cpu().numpy()\n",
    "        \n",
    "        index = np.add(index_senet,index_pnasnet)\n",
    "        index = np.add(index,index_polynet)\n",
    "        index = np.add(index,index_densenet)\n",
    "        index /=4\n",
    "        for k in index:\n",
    "            mini_batch_index = k.argsort()[::-1][:3]\n",
    "            batch_index.append(mini_batch_index)\n",
    "            \n",
    "        assert len(image_names) == len(batch_index)\n",
    "        \n",
    "        with open(\"pytorch_ensembling_4models.txt\",\"a\") as f:\n",
    "            for l in range(len(image_names)):\n",
    "                f.write(image_names[l]+','+str(batch_index[l][0])+' '+str(batch_index[l][1])+' '+\n",
    "                        str(batch_index[l][2])+'\\n')\n",
    "        data_senet = []\n",
    "        data_pnasnet = []\n",
    "        data_polynet = []\n",
    "        data_densenet = []\n",
    "        image_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('pytorch_ensembling_4models.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
