{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import shutil,os\n",
    "\n",
    "os.mkdir(\"./Train\")\n",
    "os.mkdir(\"./Valid\")\n",
    "\n",
    "val_csv = pd.read_csv(\"../input/annotations-v2/val_info_v2.csv\")\n",
    "\n",
    "src_path = \"../input/ifood-2019-fgvc6/val_set/val_set/\"\n",
    "dst_path = \"./Valid/\"\n",
    "for i in tqdm(range(len(val_csv))):\n",
    "    img = val_csv[\"ImageID\"][i]\n",
    "    cls = val_csv[\"ClassName\"][i]\n",
    "    if(os.path.exists(dst_path+cls)):\n",
    "        _=shutil.copy(src_path+img,dst_path+cls)\n",
    "    else:\n",
    "        os.mkdir(dst_path+cls)\n",
    "        _=shutil.copy(src_path+img,dst_path+cls)\n",
    "\n",
    "train_csv = pd.read_csv(\"../input/annotations-v2/train_info_v2.csv\")\n",
    "\n",
    "src_path = \"../input/ifood-2019-fgvc6/train_set/train_set/\"\n",
    "dst_path = \"./Train/\"\n",
    "for i in tqdm(range(len(train_csv))):\n",
    "    img = train_csv[\"ImageID\"][i]\n",
    "    cls = train_csv[\"ClassName\"][i]\n",
    "    if(os.path.exists(dst_path+cls)):\n",
    "        _=shutil.copy(src_path+img,dst_path+cls)\n",
    "    else:\n",
    "        os.mkdir(dst_path+cls)\n",
    "        _=shutil.copy(src_path+img,dst_path+cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pretrainedmodels\n",
    "import os,time\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import numpy as np\n",
    "import pretrainedmodels\n",
    "from tqdm import tqdm\n",
    "import torch.optim.lr_scheduler as lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./\"\n",
    "train_dir = os.path.join(data_dir,\"Train/\")\n",
    "valid_dir = os.path.join(data_dir,\"Valid/\")\n",
    "\n",
    "\n",
    "\n",
    "data_transform = {'train' : transforms.Compose([transforms.CenterCrop(331),\n",
    "                                     transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                              std=[0.229, 0.224, 0.225])]),\n",
    "\n",
    "                   'valid': transforms.Compose([transforms.Resize(size=(331,331)),\n",
    "                                     transforms.ToTensor(), \n",
    "                                     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                              std=[0.229, 0.224, 0.225])])\n",
    "    \n",
    "}\n",
    "\n",
    "train_data = datasets.ImageFolder(train_dir, transform=data_transform['train'])\n",
    "valid_data = datasets.ImageFolder(valid_dir, transform=data_transform['valid'])\n",
    "\n",
    "batch_size = 16\n",
    "num_workers = 0\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,num_workers=num_workers, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size,num_workers=num_workers, shuffle=True)\n",
    "data_loaders = {'train' : train_loader, 'valid' : valid_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if GPU is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU available: \",use_cuda)\n",
    "\n",
    "class FCWithLogSigmoid(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super(FCWithLogSigmoid, self).__init__()\n",
    "        self.linear = nn.Linear(num_inputs, num_outputs)\n",
    "        self.logsigmoid = nn.LogSigmoid()\n",
    "    def forward(self, x):\n",
    "        return self.logsigmoid(self.linear(x))\n",
    "\n",
    "#Specifying model\n",
    "model_name = 'polynet'\n",
    "model = pretrainedmodels.__dict__[model_name](pretrained=None) #pretrained='imagenet+background'\n",
    "\n",
    "\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.last_linear = FCWithLogSigmoid(2048, 251)\n",
    "\n",
    "# for param in model.last_linear.parameters():\n",
    "#     param.requires_grad=True\n",
    "    \n",
    "# for param in model.stage_b.parameters():\n",
    "#     param.requires_grad=True\n",
    "    \n",
    "# for param in model.reduction_b.parameters():\n",
    "#     param.requires_grad=True\n",
    "    \n",
    "# for param in model.stage_c.parameters():\n",
    "#     param.requires_grad=True\n",
    "    \n",
    "model.load_state_dict(torch.load('../input/models-aug/pytorch_polynet.pt'))\n",
    "\n",
    "if use_cuda:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss().cuda()\n",
    "optimizer = optim.Adam(model.parameters(),amsgrad=True,lr=1e-4,betas=(0.9, 0.999),\n",
    "                       eps=1e-8,weight_decay=0.0) \n",
    "scheduler = lr_scheduler.MultiStepLR(optimizer,milestones=[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        start = time.time()\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        correct = 0.\n",
    "        total = 0.\n",
    "\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in tqdm(enumerate(loaders['train'])):\n",
    "            # move to GPU\n",
    "            target=target.numpy()\n",
    "            tar = np.zeros((target.size, 251), dtype=int)\n",
    "            tar[np.arange(target.size), target] = 1\n",
    "            target=torch.from_numpy(tar)\n",
    "            target= target.float()\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "\n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            model.eval()\n",
    "            for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "                # move to GPU\n",
    "                target=target.numpy()\n",
    "                tar = np.zeros((target.size, 251), dtype=int)\n",
    "                tar[np.arange(target.size), target] = 1\n",
    "                target=torch.from_numpy(tar)\n",
    "                target= target.float()\n",
    "                \n",
    "                if use_cuda:\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "                ## update the average validation loss\n",
    "                # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                output = model(data)\n",
    "                # calculate the batch loss\n",
    "                loss = criterion(output, target)\n",
    "                valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "                # convert output probabilities to predicted class\n",
    "                pred = output.data.max(1, keepdim=True)[1]\n",
    "                # compare predictions to true label\n",
    "                target=target.cpu().numpy()\n",
    "                target = [np.where(r==1)[0][0] for r in target]\n",
    "                pred = pred.cpu().numpy()\n",
    "                for i in range(len(target)):\n",
    "                    if(target[i]==pred[i]):\n",
    "                        correct+=1\n",
    "                        total+=1\n",
    "                    else:\n",
    "                        total+=1\n",
    "                \n",
    "\n",
    "        accuracy = (100. * correct / total)\n",
    "        end = time.time()\n",
    "        epoch_time = (end-start)/60\n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\\n",
    "              \\tValidation Accuracy: {:.4f} \\tTime taken in min : {:.4f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss,\n",
    "            accuracy,\n",
    "            epoch_time\n",
    "            ))\n",
    "\n",
    "        ## save the model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "            \n",
    "        scheduler.step(valid_loss)\n",
    "            \n",
    "    # return trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "n_epochs = 3\n",
    "model = train(n_epochs, data_loaders, model, optimizer, criterion, use_cuda, 'pytorch_polynet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('pytorch_polynet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making predictions on test data by making batches manually\n",
    "from PIL import Image\n",
    "test_path = \"../input/ifood-2019-fgvc6/test_set/test_set/\"\n",
    "batch_size = 64\n",
    "test_images = os.listdir(test_path)\n",
    "images_complete = test_images[:(len(os.listdir(test_path))//batch_size)*batch_size]\n",
    "images_partial = test_images[(len(os.listdir(test_path))//batch_size)*batch_size:]\n",
    "\n",
    "transform = transforms.Compose([transforms.CenterCrop(331),\n",
    "                                 transforms.ToTensor(), \n",
    "                                 transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                          std=[0.229, 0.224, 0.225])])\n",
    "  \n",
    "\n",
    "data = []\n",
    "image_names = []\n",
    "for i in tqdm(range(len(images_complete))):\n",
    "    image = Image.open(test_path+images_complete[i])\n",
    "    image = transform(image).float()\n",
    "    image = image.unsqueeze(0)\n",
    "    data.append(image)\n",
    "    image_names.append(images_complete[i])\n",
    "\n",
    "    if (len(data) == batch_size):\n",
    "        t = 0\n",
    "        batch_index = []\n",
    "        first_tensor_data = data[t]\n",
    "        while(t<(batch_size-1)):\n",
    "            second_tensor_data = data[t+1]\n",
    "            data_tensor = torch.cat((first_tensor_data,second_tensor_data),dim=0)\n",
    "            first_tensor_data = data_tensor\n",
    "            t+=1\n",
    "        if use_cuda:\n",
    "            data_tensor = data_tensor.cuda()\n",
    "        output = model(data_tensor)\n",
    "        index = output.data.cpu().numpy()\n",
    "        for k in index:\n",
    "            mini_batch_index = k.argsort()[::-1][:3]\n",
    "            batch_index.append(mini_batch_index)\n",
    "            \n",
    "        assert len(image_names) == len(batch_index)\n",
    "        \n",
    "        with open(\"pytorch_polynet.txt\",\"a\") as f:\n",
    "            for l in range(len(image_names)):\n",
    "                f.write(image_names[l]+','+str(batch_index[l][0])+' '+str(batch_index[l][1])+' '+\n",
    "                        str(batch_index[l][2])+'\\n')\n",
    "        data = []\n",
    "        image_names = []\n",
    "\n",
    "data = []\n",
    "image_names = []\n",
    "for i in tqdm(range(len(images_partial))):\n",
    "    image = Image.open(test_path+images_partial[i])\n",
    "    image = transform(image).float()\n",
    "    image = image.unsqueeze(0)\n",
    "    data.append(image)\n",
    "    image_names.append(images_partial[i])\n",
    "\n",
    "    if (len(data) == len(images_partial)):\n",
    "        t = 0\n",
    "        batch_index = []\n",
    "        first_tensor_data = data[t]\n",
    "        while(t<(len(images_partial)-1)):\n",
    "            second_tensor_data = data[t+1]\n",
    "            data_tensor = torch.cat((first_tensor_data,second_tensor_data),dim=0)\n",
    "            first_tensor_data = data_tensor\n",
    "            t+=1\n",
    "        if use_cuda:\n",
    "            data_tensor = data_tensor.cuda()\n",
    "        output = model(data_tensor)\n",
    "        index = output.data.cpu().numpy()\n",
    "        for k in index:\n",
    "            mini_batch_index = k.argsort()[::-1][:3]\n",
    "            batch_index.append(mini_batch_index)\n",
    "            \n",
    "        assert len(image_names) == len(batch_index)\n",
    "        \n",
    "        with open(\"pytorch_polynet.txt\",\"a\") as f:\n",
    "            for l in range(len(image_names)):\n",
    "                f.write(image_names[l]+','+str(batch_index[l][0])+' '+str(batch_index[l][1])+' '+\n",
    "                        str(batch_index[l][2])+'\\n')\n",
    "        data = []\n",
    "        image_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('pytorch_polynet.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
