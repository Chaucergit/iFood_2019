{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages\n",
    "!pip install pretrainedmodels\n",
    "import pandas as pd\n",
    "import os,time,random,cv2,shutil\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import numpy as np\n",
    "import pretrainedmodels\n",
    "from tqdm import tqdm\n",
    "import torch.optim.lr_scheduler as lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making data folders \n",
    "os.mkdir(\"./Train\")\n",
    "os.mkdir(\"./Valid\")\n",
    "\n",
    "val_csv = pd.read_csv(\"../input/annotations-v2/val_info_v2.csv\")\n",
    "\n",
    "src_path = \"../input/ifood-2019-fgvc6/val_set/val_set/\"\n",
    "dst_path = \"./Valid/\"\n",
    "for i in tqdm(range(len(val_csv))):\n",
    "    img = val_csv[\"ImageID\"][i]\n",
    "    cls = val_csv[\"ClassName\"][i]\n",
    "    if(os.path.exists(dst_path+cls)):\n",
    "        _=shutil.copy(src_path+img,dst_path+cls)\n",
    "    else:\n",
    "        os.mkdir(dst_path+cls)\n",
    "        _=shutil.copy(src_path+img,dst_path+cls)\n",
    "\n",
    "#Removing outliers\n",
    "outliers = []\n",
    "with open(\"./../input/annotations-v2/outliers.txt\",\"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        outliers.append(line.split(\"\\n\")[0])\n",
    "train_csv = pd.read_csv(\"../input/annotations-v2/train_info_v2.csv\")\n",
    "\n",
    "src_path = \"../input/ifood-2019-fgvc6/train_set/train_set/\"\n",
    "dst_path = \"./Train/\"\n",
    "for i in tqdm(range(len(train_csv))):\n",
    "    img = train_csv[\"ImageID\"][i]\n",
    "    if img in outliers:\n",
    "        continue\n",
    "    cls = train_csv[\"ClassName\"][i]\n",
    "    if(os.path.exists(dst_path+cls)):\n",
    "        _=shutil.copy(src_path+img,dst_path+cls)\n",
    "    else:\n",
    "        os.mkdir(dst_path+cls)\n",
    "        _=shutil.copy(src_path+img,dst_path+cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions for augmentation\n",
    "def rotateImage(image):\n",
    "    angle = np.random.randint(-25,25)\n",
    "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    return result\n",
    "\n",
    "def brightness_more(image, factor=10):\n",
    "    matrix = np.ones(image.shape, dtype = \"uint8\") * factor\n",
    "    added = cv2.add(image, matrix)\n",
    "    return added\n",
    "\n",
    "def brightness_less(image, factor=10):\n",
    "    matrix = np.ones(image.shape, dtype = \"uint8\") * factor\n",
    "    subtracted = cv2.subtract(image, matrix)\n",
    "    return subtracted\n",
    "\n",
    "def hflip_image(image):\n",
    "    return cv2.flip(image,1)\n",
    "\n",
    "def contrast(image):\n",
    "    #Converting image to LAB Color model\n",
    "    lab= cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    #Splitting the LAB image to different channels\n",
    "    l, a, b = cv2.split(lab)\n",
    "    #Applying CLAHE to L-channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    cl = clahe.apply(l)\n",
    "    #Merge the CLAHE enhanced L-channel with the a and b channel\n",
    "    limg = cv2.merge((cl,a,b))\n",
    "    #Converting image from LAB Color model to RGB model\n",
    "    final = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augmenting the data\n",
    "AUGMENTATIONS = [rotateImage,brightness_more,brightness_less,hflip_image,contrast]\n",
    "new = 0\n",
    "for classes in tqdm(os.listdir(\"./Train\")):\n",
    "    NUMBER_OF_IMAGES = len(os.listdir(\"./Train/\"+classes))\n",
    "    if (NUMBER_OF_IMAGES <= 100):\n",
    "        #augmenting 200%\n",
    "        REQ_IMAGES = int(NUMBER_OF_IMAGES + (NUMBER_OF_IMAGES*2.0))\n",
    "            \n",
    "    elif (NUMBER_OF_IMAGES < 300 and NUMBER_OF_IMAGES >= 200):\n",
    "        #augmenting 100%\n",
    "        REQ_IMAGES = int(NUMBER_OF_IMAGES + (NUMBER_OF_IMAGES*1.0))\n",
    "            \n",
    "    elif (NUMBER_OF_IMAGES < 350 and NUMBER_OF_IMAGES >= 300):\n",
    "        #augmenting 50%\n",
    "        REQ_IMAGES = int(NUMBER_OF_IMAGES + (NUMBER_OF_IMAGES*0.5))\n",
    "\n",
    "    elif (NUMBER_OF_IMAGES < 400 and NUMBER_OF_IMAGES >= 350):\n",
    "        #augmenting 30%\n",
    "        REQ_IMAGES = int(NUMBER_OF_IMAGES + (NUMBER_OF_IMAGES*0.3))\n",
    "            \n",
    "    elif (NUMBER_OF_IMAGES < 450 and NUMBER_OF_IMAGES >= 400):\n",
    "        #augmenting 10%\n",
    "        REQ_IMAGES = int(NUMBER_OF_IMAGES + (NUMBER_OF_IMAGES*0.1))\n",
    "            \n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    while(len(os.listdir(\"./Train/\"+classes)) != REQ_IMAGES):\n",
    "        NUMBER_OF_AUGMENTATIONS = np.random.randint(1,len(AUGMENTATIONS)+1)\n",
    "        ORIGINAL_IMAGE = random.choice(os.listdir(\"./Train/\"+classes))\n",
    "        ORIG_IMG = cv2.imread(\"./Train/\"+classes+\"/\"+ORIGINAL_IMAGE)\n",
    "        for i in range(NUMBER_OF_AUGMENTATIONS):\n",
    "            AUG = random.choice(AUGMENTATIONS)\n",
    "            NEW_IMG = AUG(ORIG_IMG)\n",
    "            ORIG_IMG = NEW_IMG\n",
    "        cv2.imwrite(\"./Train/\"+classes+\"/\"+ORIGINAL_IMAGE.split(\".\")[0]+\"_\"+str(new)+\".jpg\",NEW_IMG)\n",
    "        new+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
